{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import IterableDataset, Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from data import load_labels, load_frames\n",
    "from visualize import plot_outcome_distribution\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(reduce_fps_factor, downscale_factor):\n",
    "    settings = pd.read_csv(f'./data/experiments_settings.csv')\n",
    "    for exp in [\"a\", \"b\", \"c\", \"d\", \"e\"]:\n",
    "        print(f\"Loading experiment {exp}\")\n",
    "        for pos in range(1, 10):\n",
    "            print(f\"Loading position {pos}\")\n",
    "            start_frame = int(settings[settings.Experiment == f'{exp}{pos}']['Starting Frame'].values[0]/reduce_fps_factor)\n",
    "            end_frame = int(settings[settings.Experiment == f'{exp}{pos}']['End Frame Annotation'].values[0]/reduce_fps_factor)\n",
    "            treatment = settings[settings.Experiment == f'{exp}{pos}']['Treatment'].values[0].astype(int)\n",
    "            # load file .mkv\n",
    "            frames = load_frames(exp, pos, \n",
    "                                 reduce_fps_factor=reduce_fps_factor, \n",
    "                                 downscale_factor=downscale_factor, \n",
    "                                 start_frame=start_frame, \n",
    "                                 end_frame=end_frame)\n",
    "            # load annotations\n",
    "            labels = load_labels(exp, pos, \n",
    "                                 reduce_fps_factor=reduce_fps_factor,\n",
    "                                 start_frame=start_frame,\n",
    "                                 end_frame=end_frame)\n",
    "            for i in range(end_frame-start_frame):\n",
    "                yield {\n",
    "                    \"experiment\": exp,\n",
    "                    \"position\": pos,\n",
    "                    \"frame\": i,\n",
    "                    \"image\": frames[i],\n",
    "                    \"treatment\": treatment,\n",
    "                    \"outcome\": labels[i,:],\n",
    "                }\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_generator(generator, gen_kwargs={\"reduce_fps_factor\": 10, \"downscale_factor\": 0.4})\n",
    "dataset.save_to_disk(\"./data/train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = Dataset.load_from_disk(\"./data/train\")\n",
    "train.set_format(type=\"torch\", columns=[\"image\", \"treatment\", \"outcome\"], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outcome_distribution(train, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# logits = outputs.logits\n",
    "# print(\"Top 5 predicted labels with associated probabilities:\")\n",
    "# top_5 = torch.topk(logits, 5)\n",
    "# probs = logits.softmax(-1)[0][top_5.indices][0]\n",
    "# for i, (idx, prob) in enumerate(zip(top_5.indices[0], probs), 1):\n",
    "#     print(f\"    {i}. {model.config.id2label[idx.item()]}: {prob.item():.2%}\")\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "\n",
    "inputs = processor(images=input, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hidden_states[-1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column 'emb1' using map-style function \n",
    "train = train.map(lambda x: {\"emb1\": x['image']*10}, batch_size=600, batched=True, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable_dataset = IterableDataset.from_generator(generator, gen_kwargs={\"reduce_fps_factor\": 10, \"downscale_factor\": 0.5})\n",
    "dataset = iterable_dataset.to_dataset()\n",
    "dataset.save_to_disk(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=3, num_workers=0)\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a generator function\n",
    "def my_generator(n, sources):\n",
    "    for source in sources:\n",
    "        for example_id_for_current_source in range(n):\n",
    "            yield {\"example_id\": f\"{source}_{example_id_for_current_source}\"}\n",
    "\n",
    "gen_kwargs = {\"n\": 10, \"sources\": [f\"path/to/data_{i}\" for i in range(1024)]}\n",
    "my_iterable_dataset = IterableDataset.from_generator(my_generator, gen_kwargs=gen_kwargs)\n",
    "my_iterable_dataset.n_shards  # 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained_encoder = torchvision.models.resnet50(pretrained=True).eval().requires_grad_(False)\n",
    "        self.linear = nn.Linear(1000, 10)\n",
    "\n",
    "def forward(x):\n",
    "    with torch.no_grad():\n",
    "        emb1 = self.pretrained_encoder(x['image'])\n",
    "    logits = self.linear(emb1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
