{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data import load_data\n",
    "from visualize import plot_outcome_distribution\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(environment='train', \n",
    "                    path_dir=\"./data/\", \n",
    "                    generate=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, model, processor):\n",
    "    inputs = processor(images=x, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    return outputs.hidden_states[-1][:,0]  \n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "train = train.map(lambda x: {\"emb1\": encoder(x['image'], model, processor)}, batch_size=100, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# logits = outputs.logits\n",
    "# print(\"Top 5 predicted labels with associated probabilities:\")\n",
    "# top_5 = torch.topk(logits, 5)\n",
    "# probs = logits.softmax(-1)[0][top_5.indices][0]\n",
    "# for i, (idx, prob) in enumerate(zip(top_5.indices[0], probs), 1):\n",
    "#     print(f\"    {i}. {model.config.id2label[idx.item()]}: {prob.item():.2%}\")\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "\n",
    "inputs = processor(images=input, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "outputs.hidden_states[-1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable_dataset = IterableDataset.from_generator(generator, gen_kwargs={\"reduce_fps_factor\": 10, \"downscale_factor\": 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=3, num_workers=0)\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a generator function\n",
    "def my_generator(n, sources):\n",
    "    for source in sources:\n",
    "        for example_id_for_current_source in range(n):\n",
    "            yield {\"example_id\": f\"{source}_{example_id_for_current_source}\"}\n",
    "\n",
    "gen_kwargs = {\"n\": 10, \"sources\": [f\"path/to/data_{i}\" for i in range(1024)]}\n",
    "my_iterable_dataset = IterableDataset.from_generator(my_generator, gen_kwargs=gen_kwargs)\n",
    "my_iterable_dataset.n_shards  # 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained_encoder = torchvision.models.resnet50(pretrained=True).eval().requires_grad_(False)\n",
    "        self.linear = nn.Linear(1000, 10)\n",
    "\n",
    "def forward(x):\n",
    "    with torch.no_grad():\n",
    "        emb1 = self.pretrained_encoder(x['image'])\n",
    "    logits = self.linear(emb1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
