{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('./src')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data import PPCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "encoder = \"dino\"\n",
    "dataset = PPCI(encoder = encoder,\n",
    "               token = \"class\",\n",
    "               task = \"or\",\n",
    "               split_criteria = \"position_easy\",\n",
    "               environment = \"supervised\",\n",
    "               batch_size = 64,\n",
    "               num_proc = 4,\n",
    "               verbose = True,\n",
    "               data_dir = 'data/istant_hq',\n",
    "               results_dir = f'results/istant_hq/{encoder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example train\n",
    "dataset.train(add_pred_env=\"supervised\", \n",
    "            hidden_layers = 1,\n",
    "            hidden_nodes = 256,\n",
    "            batch_size = 128,\n",
    "            lr = 0.0005,\n",
    "            num_epochs=15,\n",
    "            save = False,\n",
    "            verbose=True,\n",
    "            multidomain=True,\n",
    "            ic_weight=0,\n",
    "            seed=1)\n",
    "dataset.evaluate(color=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment Universal CRL\n",
    "exp = \"pos14\"\n",
    "encoder = \"dino\"\n",
    "\n",
    "ic_weights = [0] + list(np.logspace(-1, 4, num=16))  #[0, 0.1, 1, 10, 100, 1000, 10000]\n",
    "seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "dataset = PPCI(encoder = encoder,\n",
    "               token = \"class\",\n",
    "               task = \"or\",\n",
    "               split_criteria = \"position\",\n",
    "               environment = \"supervised\",\n",
    "               batch_size = 64,\n",
    "               num_proc = 4,\n",
    "               verbose = False,\n",
    "               data_dir = 'data/istant_hq',\n",
    "               results_dir = f'results/istant_hq/{encoder}')\n",
    "all_metrics = pd.DataFrame(columns=['ic_weight', 'seed', \"inv_loss_val\", \"loss_val\", \"acc_val\", \"bacc_val\", \"TEB_val\", \"acc\", \"bacc\", \"TEB\", \"TEB_bin\", \"EAD\", \"best_epoch\"])\n",
    "i = 0\n",
    "for ic_weight in ic_weights:\n",
    "    print(f\"IC weight: {ic_weight}\")\n",
    "    for seed in seeds:\n",
    "        print(f\"Seed: {seed}\")\n",
    "        dataset.train(add_pred_env=\"supervised\", \n",
    "                    hidden_layers = 1,\n",
    "                    hidden_nodes = 256,\n",
    "                    batch_size = 128,\n",
    "                    lr = 0.0005,\n",
    "                    num_epochs=15,\n",
    "                    verbose=False,\n",
    "                    multidomain=True,\n",
    "                    ic_weight=ic_weight,\n",
    "                    seed=seed)\n",
    "        all_metrics_i = dataset.evaluate(color=None, verbose=False)\n",
    "        all_metrics_i['ic_weight'] = ic_weight\n",
    "        all_metrics_i['seed'] = seed\n",
    "        all_metrics_i['best_epoch'] = dataset.model.best_epoch \n",
    "        all_metrics.loc[i] = all_metrics_i\n",
    "        i += 1\n",
    "\n",
    "all_metrics['TERB'] = abs(all_metrics['TEB'])/all_metrics['EAD']*100\n",
    "all_metrics.to_csv(f'results/istant_hq/{encoder}/invariance_{exp}.csv', index=False)\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "exp = \"pos14\"\n",
    "encoder = \"dino\"\n",
    "\n",
    "all_metrics = pd.read_csv(f\"results/istant_hq/{encoder}/invariance_{exp}.csv\")\n",
    "all_metrics[\"univ_loss_val\"] = all_metrics[\"loss_val\"] + all_metrics[\"inv_loss_val\"]\n",
    "all_metrics[\"TEAB_val\"] = abs(all_metrics[\"TEB_val\"])\n",
    "\n",
    "# plot the TERB vs ic_weight averaging over seeds\n",
    "plt.figure()\n",
    "plt.xlabel(r\"$\\lambda_{INV}$\")\n",
    "plt.ylabel(\"TERB (%)\", color='tab:blue')\n",
    "plt.xscale('log')\n",
    "all_metrics['ic_weight'] = all_metrics['ic_weight'].replace(0, 0.01)\n",
    "plt.errorbar(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['TERB'].mean(), yerr=all_metrics.groupby('ic_weight')['TERB'].std(), fmt='o', color='tab:blue')\n",
    "plt.plot(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['TERB'].mean(), '--', color='tab:blue')\n",
    "plt.fill_between(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['TERB'].mean()-all_metrics.groupby('ic_weight')['TERB'].std(), all_metrics.groupby('ic_weight')['TERB'].mean()+all_metrics.groupby('ic_weight')['TERB'].std(), alpha=0.2, color='skyblue')\n",
    "\n",
    "idx = all_metrics.groupby('ic_weight')[\"loss_val\"].mean().idxmin() == all_metrics[\"ic_weight\"]\n",
    "idx = all_metrics[idx][\"loss_val\"].idxmin()\n",
    "plt.plot(all_metrics.loc[idx]['ic_weight'], all_metrics.loc[idx]['TERB'], 'y*', markersize=12, alpha=1, color=\"orange\", label=\"Min ERM\", zorder=10, clip_on=False, markeredgecolor='tab:blue', markeredgewidth=1)\n",
    "\n",
    "idx = all_metrics.groupby('ic_weight')[\"inv_loss_val\"].mean().idxmin() == all_metrics[\"ic_weight\"]\n",
    "idx = all_metrics[idx][\"inv_loss_val\"].idxmin()\n",
    "plt.plot(all_metrics.loc[idx]['ic_weight'], all_metrics.loc[idx]['TERB'], 'y*', markersize=12, alpha=1, color=\"purple\", label=\"Min Invariance\", zorder=10, clip_on=False, markeredgecolor='tab:blue', markeredgewidth=1)\n",
    "\n",
    "idx = all_metrics.groupby('ic_weight')[\"TEAB_val\"].mean().idxmin() == all_metrics[\"ic_weight\"]\n",
    "idx = all_metrics[idx][\"TEAB_val\"].idxmin()\n",
    "plt.plot(all_metrics.loc[idx]['ic_weight'], all_metrics.loc[idx]['TERB'], 'y*', markersize=12, alpha=1, color=\"green\", label=\"Min TERB\", zorder=10, clip_on=False, markeredgecolor='tab:blue', markeredgewidth=1)\n",
    "\n",
    "plt.ylim(0, 140)\n",
    "plt.legend(loc='upper left', framealpha=1, title=f\"Model Selection Criteria\",# ($on$ $validation$)\", \n",
    "           title_fontsize=\"8.5\", fontsize=\"8\", alignment=\"left\") \n",
    "plt.xticks([0.01, 0.1, 1, 10, 100, 1000, 10000], [f\"0\\n(ERM)\", 0.1, 1, 10, 100, 1000, 10000]);\n",
    "\n",
    "plt.twinx()\n",
    "plt.ylabel(\"Balanced Accuracy\", color='tab:red')\n",
    "plt.errorbar(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['bacc'].mean(), yerr=all_metrics.groupby('ic_weight')['bacc'].std(), fmt='o', color='tab:red', label=\"Accuracy\");\n",
    "plt.plot(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['bacc'].mean(), '--', color='tab:red', label=\"Balanced Accuracy\");\n",
    "plt.fill_between(all_metrics['ic_weight'].unique(), all_metrics.groupby('ic_weight')['bacc'].mean()-all_metrics.groupby('ic_weight')['bacc'].std(), all_metrics.groupby('ic_weight')['bacc'].mean()+all_metrics.groupby('ic_weight')['bacc'].std(), alpha=0.2, color='pink')\n",
    "plt.ylim(0.45, 1)\n",
    "plt.axvline(x=0.031622776601683794, color='black', linestyle='--', label=r\"separation\", alpha=0.2)\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(f\"results/istant_hq/{encoder}/invariance_{exp}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train_metrics to numpy array\n",
    "train_metrics = np.squeeze(np.array(train_metrics)) # ic x epochs x metrics\n",
    "val_metrics = np.squeeze(np.array(val_metrics)) # ic x epochs x metrics\n",
    "\n",
    "# 6 plots: accuracy, precision, recall vs epochs varying ic_weight (for train and val)\n",
    "metrics = ['accuracy', 'precision', 'recall']\n",
    "colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    for j, ic_weight in enumerate(ic_weights):\n",
    "        plt.plot(train_metrics[j, :, i], color=colors[j], label=f'ic_weight={ic_weight}')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Training', fontsize=16, y=1.05)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    for j, ic_weight in enumerate(ic_weights):\n",
    "        plt.plot(val_metrics[j, :, i], color=colors[j], label=f'ic_weight={ic_weight}')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Validation', fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_metrics, index=ic_weights)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "n = dataset.supervised[\"X\"].shape[0]\n",
    "pairs = []\n",
    "labels = []\n",
    "for i in range(n):  \n",
    "    if env_id[i] == env_id[i+1]:\n",
    "        pairs.append((dataset.supervised[\"X\"][i], dataset.supervised[\"X\"][i+1]))\n",
    "        labels.append(1)\n",
    "    env_avg_len = n // len(np.unique(env_id))\n",
    "    k = round(i+env_avg_len*1.5)%n\n",
    "    pairs.append((dataset.supervised[\"X\"][i], dataset.supervised[\"X\"][k]))\n",
    "    labels.append(1)\n",
    "DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.supervised[\"T\"][dataset.supervised[\"split\"]]==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 0\n",
    "pos = 6\n",
    "frame = 720\n",
    "\n",
    "frame_id = ((dataset.supervised[\"source_data\"][\"experiment\"] == exp) & (dataset.supervised[\"source_data\"][\"position\"] == pos) & (dataset.supervised[\"source_data\"][\"frame\"] == frame)).nonzero(as_tuple=True)[0][0].item()\n",
    "img = dataset.supervised[\"source_data\"][frame_id][\"image\"] # shape 3, 770, 770\n",
    "print(dataset.supervised[\"W\"][frame])\n",
    "print(dataset.supervised[\"Y\"][frame])\n",
    "# remove ticks\n",
    "plt.axis('off')\n",
    "plt.imshow(img.permute(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 0\n",
    "pos = 6\n",
    "frame = 450\n",
    "\n",
    "frame_id = ((dataset.supervised[\"source_data\"][\"experiment\"] == exp) & (dataset.supervised[\"source_data\"][\"position\"] == pos) & (dataset.supervised[\"source_data\"][\"frame\"] == frame)).nonzero(as_tuple=True)[0][0].item()\n",
    "img1 = dataset.supervised[\"source_data\"][frame_id][\"image\"] # shape 3, 770, 770\n",
    "print(dataset.supervised[\"Y\"][frame_id])\n",
    "\n",
    "exp = 0\n",
    "pos = 6\n",
    "frame = 720\n",
    "\n",
    "frame_id = ((dataset.supervised[\"source_data\"][\"experiment\"] == exp) & (dataset.supervised[\"source_data\"][\"position\"] == pos) & (dataset.supervised[\"source_data\"][\"frame\"] == frame)).nonzero(as_tuple=True)[0][0].item()\n",
    "img2 = dataset.supervised[\"source_data\"][frame_id][\"image\"] # shape 3, 770, 770\n",
    "print(dataset.supervised[\"Y\"][frame_id])\n",
    "\n",
    "# plot the 2 images\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1.permute(1, 2, 0))\n",
    "ax[1].imshow(img2.permute(1, 2, 0))\n",
    "# remove ticks\n",
    "for a in ax:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "# attach the plot closer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.evaluate(color=\"blue\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal import compute_ate\n",
    "compute_ate(dataset.supervised[\"Y_hat\"], \n",
    "            dataset.supervised[\"T\"], \n",
    "            dataset.supervised[\"W\"], \n",
    "            method=\"ead\", \n",
    "            color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = PPCI()\n",
    "# dataset.plot_out_distribution()\n",
    "# dataset.train()\n",
    "# dataset.visualize()\n",
    "# dataset.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = (dataset.supervised[\"source_data\"][\"experiment\"]==4)\n",
    "pos = (dataset.supervised[\"source_data\"][\"position\"]==1)\n",
    "filter = (exp & pos).nonzero().squeeze()\n",
    "y = dataset.supervised[\"Y\"][filter][:,0].detach()\n",
    "y_hat = dataset.supervised[\"Y_hat\"][filter][:,0].detach()\n",
    "y_pred = y_hat.round()\n",
    "\n",
    "plt.scatter(range(len(filter)), y_hat, s=1, c=\"blue\", alpha=0.5, label=\"y_probs\")\n",
    "plt.scatter(range(len(filter)),y_pred-(-1)**y_pred.detach()*0.04, s=1, c=\"red\", alpha=0.5, label=\"y_pred\")\n",
    "plt.scatter(range(len(filter)), y-(-1)**y.detach()*0.02, s=1, c=\"green\", alpha=0.5, label=\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = (dataset.supervised[\"source_data\"][\"frame\"]==2220)\n",
    "idx = (exp & pos & frame).nonzero().item()\n",
    "img = dataset.supervised[\"source_data\"][idx][\"image\"]\n",
    "outcome = dataset.supervised[\"source_data\"][idx][\"outcome\"]\n",
    "\n",
    "img = img.permute(1, 2, 0)\n",
    "plt.title(f\"Y2F: {int(outcome[0])}, B2F: {int(outcome[1])}\")\n",
    "plt.imshow(img);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
